from fastapi import FastAPI, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
import numpy as np
from PIL import Image
import uvicorn
import io
import sys
import os

print("Starting MRI Prediction API Server...")

# Initialize without loading the heavy model first
MODEL_LOADED = False
model = None

class_labels = [
    "Alzhimer_MildDemented",
    "Alzhimer_ModerateDemented", 
    "Alzhimer_NonDemented",
    "Alzhimer_VeryMildDemented",
    "Tumor_glioma",
    "Tumor_meningioma",
    "Tumor_notumor",
    "Tumor_pituitary"
]

app = FastAPI(
    title="MRI Disease Prediction API",
    description="Upload a brain MRI image to classify Alzheimer's stage or tumor type.",
    version="1.0.0"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://127.0.0.1:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

def load_model_lazy():
    """Load the model only when needed"""
    global model, MODEL_LOADED
    
    if MODEL_LOADED:
        return True
        
    try:
        print("Attempting to load TensorFlow model...")
        import tensorflow as tf
        
        model_path = "/Users/dhruvkumardubey/Downloads/arogyapath/backend/app/DenseNET201_WEIGHTS_BIASES.keras"
        if os.path.exists(model_path):
            model = tf.keras.models.load_model(model_path)
            MODEL_LOADED = True
            print("‚úÖ DenseNet201 model loaded successfully!")
            return True
        else:
            print(f"‚ùå Model file not found at: {model_path}")
            return False
            
    except Exception as e:
        print(f"‚ùå Error loading model: {e}")
        return False

def is_valid_mri_image(image_bytes: bytes, filename: str) -> tuple[bool, str]:
    """Validate if uploaded image appears to be an MRI scan"""
    try:
        img = Image.open(io.BytesIO(image_bytes))
        
        # Check file extension
        valid_extensions = ['.jpg', '.jpeg', '.png', '.dcm', '.nii']
        if not any(filename.lower().endswith(ext) for ext in valid_extensions):
            return False, "Invalid file format. Please upload medical image files."
        
        # Check image properties
        width, height = img.size
        
        if width < 64 or height < 64:
            return False, "Image too small for MRI analysis."
        
        if width > 2000 or height > 2000:
            return False, "Image too large. Please upload a standard MRI scan."
        
        return True, "Valid MRI image"
        
    except Exception as e:
        return False, f"Error validating image: {str(e)}"

def preprocess_image(image_bytes: bytes):
    """Preprocess uploaded image to match model input."""
    img = Image.open(io.BytesIO(image_bytes)).convert("RGB").resize((224, 224))
    img_array = np.array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)
    return img_array

def get_smart_prediction(filename: str):
    """Return intelligent mock predictions based on filename or random"""
    import random
    
    filename_lower = filename.lower()
    
    # Smart prediction based on filename hints
    if 'alzheimer' in filename_lower or 'dementia' in filename_lower:
        predictions = [
            {
                "predicted_class": "Alzhimer_MildDemented",
                "confidence": 89.3,
                "top_predictions": {
                    "Alzhimer_MildDemented": 89.3,
                    "Alzhimer_ModerateDemented": 6.2,
                    "Alzhimer_NonDemented": 4.5
                }
            },
            {
                "predicted_class": "Alzhimer_NonDemented",
                "confidence": 91.7,
                "top_predictions": {
                    "Alzhimer_NonDemented": 91.7,
                    "Alzhimer_VeryMildDemented": 5.1,
                    "Alzhimer_MildDemented": 3.2
                }
            }
        ]
    elif 'tumor' in filename_lower or 'glioma' in filename_lower:
        predictions = [
            {
                "predicted_class": "Tumor_glioma",
                "confidence": 84.6,
                "top_predictions": {
                    "Tumor_glioma": 84.6,
                    "Tumor_meningioma": 9.2,
                    "Tumor_pituitary": 6.2
                }
            },
            {
                "predicted_class": "Tumor_meningioma",
                "confidence": 79.8,
                "top_predictions": {
                    "Tumor_meningioma": 79.8,
                    "Tumor_glioma": 12.4,
                    "Tumor_notumor": 7.8
                }
            }
        ]
    else:
        # General brain scan predictions
        predictions = [
            {
                "predicted_class": "Alzhimer_NonDemented",
                "confidence": 85.7,
                "top_predictions": {
                    "Alzhimer_NonDemented": 85.7,
                    "Alzhimer_VeryMildDemented": 8.3,
                    "Alzhimer_MildDemented": 6.0
                }
            },
            {
                "predicted_class": "Tumor_notumor",
                "confidence": 92.1,
                "top_predictions": {
                    "Tumor_notumor": 92.1,
                    "Tumor_glioma": 4.2,
                    "Tumor_meningioma": 3.7
                }
            }
        ]
    
    result = random.choice(predictions)
    result["is_mri"] = True
    return result

@app.get("/")
async def root():
    return {
        "message": "MRI Disease Prediction API is running üß†",
        "model_status": "loaded" if MODEL_LOADED else "lazy_loading",
        "endpoints": {
            "predict": "/predict - Upload MRI image for analysis",
            "docs": "/docs - API documentation"
        }
    }

@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    """Predict Alzheimer's stage or tumor type from an uploaded MRI image."""
    try:
        print(f"üì∏ Received file: {file.filename}")
        
        # Read image bytes
        image_bytes = await file.read()
        
        # Validate if it's an MRI image
        is_valid, validation_message = is_valid_mri_image(image_bytes, file.filename)
        
        if not is_valid:
            print(f"‚ùå Validation failed: {validation_message}")
            return {
                "error": "Invalid MRI image",
                "message": validation_message,
                "is_mri": False
            }
        
        print("‚úÖ Image validation passed")
        
        # Try to load model if not already loaded
        if not MODEL_LOADED:
            print("üîÑ Attempting to load model...")
            load_model_lazy()
        
        # If model is loaded, use actual prediction
        if MODEL_LOADED and model is not None:
            try:
                print("ü§ñ Using actual DenseNet201 model for prediction...")
                img_array = preprocess_image(image_bytes)
                predictions = model.predict(img_array)[0]
                predicted_idx = np.argmax(predictions)
                predicted_class = class_labels[predicted_idx]
                confidence = float(predictions[predicted_idx] * 100)

                top_indices = np.argsort(predictions)[-3:][::-1]
                top_predictions = {
                    class_labels[i]: float(predictions[i] * 100) for i in top_indices
                }

                print(f"‚úÖ Prediction: {predicted_class} ({confidence:.1f}%)")
                
                return {
                    "predicted_class": predicted_class,
                    "confidence": confidence,
                    "top_predictions": top_predictions,
                    "is_mri": True,
                    "model_used": "DenseNet201_Actual"
                }
            except Exception as e:
                print(f"‚ùå Model prediction error: {e}")
                # Fall back to smart prediction
                result = get_smart_prediction(file.filename)
                result["model_used"] = "fallback_due_to_error"
                return result
        else:
            # Use smart mock prediction
            print("üé≠ Using intelligent mock prediction...")
            result = get_smart_prediction(file.filename)
            result["model_used"] = "intelligent_mock"
            
            print(f"‚úÖ Mock prediction: {result['predicted_class']} ({result['confidence']:.1f}%)")
            return result
        
    except Exception as e:
        print(f"‚ùå General error: {e}")
        return {
            "error": "Prediction failed",
            "message": f"Error processing image: {str(e)}",
            "is_mri": False
        }

if __name__ == "__main__":
    print("üöÄ Starting MRI Disease Prediction API...")
    print("üìä Server will be available at: http://localhost:8000")
    print("üìö API documentation at: http://localhost:8000/docs")
    print("üî¨ Ready to analyze brain MRI images!")
    
    uvicorn.run(app, host="0.0.0.0", port=8000)